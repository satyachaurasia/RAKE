{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFileObj=open('JavaBasics-notes.pdf', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfReader=PyPDF2.PdfFileReader(pdfFileObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "text=''\n",
    "pages=pdfReader.numPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "while count<pages:\n",
    "    pageObj=pdfReader.getPage(count)\n",
    "    count+=1\n",
    "    text+=pageObj.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"Avatar: The Last Airbender (Avatar: The Legend of Aang in some regions) is an American animated television series that aired for three seasons on Nickelodeon. The series began in February 2005 and concluded with a two-hour episode titled Sozins Comet in July 2008. Avatar: The Last Airbender is set in an Asiatic-like world in which some people can manipulate the classical elements with psychokinetic variants of the Chinese martial \n",
    "arts known as bending. The series is presented in a style that combines anime with \n",
    "American cartoons and relies on the imagery of East-and-South Asian, Inuit, \n",
    "and New World societies. It follows the protagonist, twelve-year-old Aang and his friends,\n",
    "who must bring peace and unity to the world by ending the Fire Lords war with three nations.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=set(nltk.corpus.stopwords.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPunct(word):\n",
    "  return len(word) == 1 and word in string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNumeric(word):\n",
    "    try:\n",
    "        float(word) if '.' in word else int(word)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list=[]\n",
    "for sentence in sentences:\n",
    "    \n",
    "    words=map(lambda x: \"|\" if x in stopwords else x, nltk.word_tokenize(sentence.lower()))\n",
    "    phrase=[]\n",
    "    for word in words:\n",
    "        if word == '|' or isPunct(word):\n",
    "            if len(phrase)>0:\n",
    "                phrase_list.append(phrase)\n",
    "                phrase=[]\n",
    "        else:\n",
    "            phrase.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq=nltk.FreqDist()\n",
    "word_degree=nltk.FreqDist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phrase in phrase_list:\n",
    "    l=[lambda x: not isNumeric(x), phrase]\n",
    "    degree=len(l)-1\n",
    "    for word in phrase:\n",
    "        word_freq[word]+=1\n",
    "        word_degree[word]+=degree\n",
    "for word in word_freq.keys():\n",
    "    word_degree[word] = word_degree[word] + word_freq[word] \n",
    "word_scores = {}\n",
    "for word in word_freq.keys():\n",
    "    word_scores[word] = word_degree[word] / word_freq[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_scores = {}\n",
    "for phrase in phrase_list:\n",
    "    phrase_score = 0\n",
    "    for word in phrase:\n",
    "        phrase_score += word_scores[word]\n",
    "    phrase_scores[\" \".join(phrase)] = phrase_score    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_phrase_scores = sorted(phrase_scores.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_phrases = len(sorted_phrase_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords= sorted_phrase_scores[0:int(n_phrases/1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('two-hour episode titled sozins comet', 10.0),\n",
       " ('american animated television series', 8.0),\n",
       " ('chinese martial arts known', 8.0),\n",
       " ('new world societies', 6.0),\n",
       " ('must bring peace', 6.0),\n",
       " ('last airbender', 4.0),\n",
       " ('three seasons', 4.0),\n",
       " ('series began', 4.0),\n",
       " ('february 2005', 4.0),\n",
       " ('july 2008', 4.0),\n",
       " ('asiatic-like world', 4.0),\n",
       " ('classical elements', 4.0),\n",
       " ('psychokinetic variants', 4.0),\n",
       " ('combines anime', 4.0),\n",
       " ('american cartoons', 4.0),\n",
       " ('east-and-south asian', 4.0),\n",
       " ('twelve-year-old aang', 4.0),\n",
       " ('fire lords', 4.0),\n",
       " ('three nations', 4.0),\n",
       " ('avatar', 2.0),\n",
       " ('legend', 2.0),\n",
       " ('aang', 2.0),\n",
       " ('regions', 2.0),\n",
       " ('aired', 2.0),\n",
       " ('nickelodeon', 2.0),\n",
       " ('concluded', 2.0),\n",
       " ('set', 2.0),\n",
       " ('people', 2.0),\n",
       " ('manipulate', 2.0),\n",
       " ('bending', 2.0),\n",
       " ('series', 2.0),\n",
       " ('presented', 2.0),\n",
       " ('style', 2.0),\n",
       " ('relies', 2.0),\n",
       " ('imagery', 2.0),\n",
       " ('inuit', 2.0),\n",
       " ('follows', 2.0),\n",
       " ('protagonist', 2.0),\n",
       " ('friends', 2.0),\n",
       " ('unity', 2.0),\n",
       " ('world', 2.0),\n",
       " ('ending', 2.0)]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<map object at 0x0134BB30>\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Java', 'All', 'Rights', 'Basics', 'BasicsTopics', 'in', 'this', 'section', 'include', 'What', 'makes', 'Java', 'programs', 'portable', 'secure', 'and', 'robust', 'The', 'structure', 'of', 'Java', 'applets', 'and', 'applications', 'How', 'Java', 'applications', 'are', 'executed', 'How', 'applets', 'are', 'invoked', 'and', 'executed', 'The', 'Java', 'Language', 'Part', 'I', 'Comments', 'Declarations', 'Expressions', 'Statements', 'Garbage', 'collection', 'Java', 'SemanticsPortabilityJava', 'programs', 'are', 'portable', 'across', 'operating', 'systems', 'and', 'hardware', 'is', 'to', 'your', 'advantage', 'because', 'You', 'need', 'only', 'one', 'version', 'of', 'your', 'software', 'to', 'serve', 'a', 'broad', 'The', 'Internet', 'in', 'effect', 'becomes', 'one', 'giant', 'dynamic', 'You', 'are', 'no', 'longer', 'limited', 'by', 'your', 'particular', 'computer', 'features', 'make', 'Java', 'String', 'programs', 'The', 'language', 'The', 'Java', 'language']\n"
     ]
    }
   ],
   "source": [
    "words = [word for word in tokens if word.isalpha()]\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['java', 'jgurucom', 'rights', 'reservedjava', 'basics', 'basicstopics', 'section', 'include', 'makes', 'java', 'programs', 'portable', 'secure', 'robust', 'structure', 'java', 'applets', 'applications', 'java', 'applications', 'executed', 'applets', 'invoked', 'executed', 'java', 'language', 'part', 'comments', 'declarations', 'expressions', 'statements', 'garbage', 'collection', 'java', 'semanticsportabilityjava', 'programs', 'portable', 'across', 'operating', 'systems', 'hardware', 'environmentsportability', 'advantage', 'need', 'one', 'version', 'software', 'serve', 'broad', 'market', 'internet', 'effect', 'becomes', 'one', 'giant', 'dynamic', 'library', 'longer', 'limited', 'particular', 'computer', 'platformthree', 'features', 'make', 'java', 'string', 'programs', 'language', 'java', 'language', 'completely', 'specified', 'datatype', 'sizes', 'andformats', 'defined', 'part', 'language', 'contrast', 'cc', 'leaves', 'details', 'compiler', 'implementor', 'many', 'cc', 'programs', 'thereforejava', 'basicsjava', 'basics', 'jgurucom', 'rights', 'reservedare', 'library', 'java', 'class', 'library', 'available', 'machine', 'javaruntime']\n"
     ]
    }
   ],
   "source": [
    "tokens = [w.lower() for w in tokens]\n",
    "# remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "# remove remaining tokens that are not alphabetic\n",
    "words = [word for word in stripped if word.isalpha()]\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in words if not w in stop_words]\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
